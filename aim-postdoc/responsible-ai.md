**Responsible AI Statement**
In early 2015, I had not yet come out as gay to my friends and family.
Nonetheless, Facebook served me an ad for — ironically enough — "Out Magazine." A barrage of targeted ads for gay lifestyle products followed.
This was a deeply unsettling and upsetting experience.
As an end-user, I was mystified about the basis on which Facebook had decided to serve me these ads; no attribution receipt or general dashboard of personal advertising information was available.
Lack of visibility imposed an intense sense of vulnerability: I did not know what aspect of my privacy had been violated.
Additionally, the product design granted me minimal agency: I could block a particular ad, but could not end unwanted advertising based on my sexual orientation.
Finally, there was no option to meaningfully report the issue.
I could mark the ad as inappropriate, but could not specify why or add a written explanation.
Even more disturbingly, I came to recognize potential for intentional abuse of Facebook's ad system: a bad actor could serve stock decoy ads to gay users then innocuously harvest personal information after click through in order to unconsensually identify gay people.

Such unintended outcomes — on individuated and systemic levels — take center stage in typical discourse around AI safety [1].
I strongly believe in **transparency, user agency, and engineering accountability**.
However, while especially salient to product-driven AI, these considerations play a less day–to-day role in research-driven AI work.
Responsible AI research must attend to an additional, orthogonal dimension: **equity in access to AI skills and tools** , which are the basis for significant socio-economic power.

**Publishing software and data** and **licensing its free reuse** is an important first step toward AI equity (where possible and prudent).
However, **un-usability largely moots availability** — particularly if use requires formal training in research computing.
Meaningful, equitable AI accessibility requires our **intentional effort to streamline software installation** through containerization and/or packaging, **to**** design for outside non-expert operability**— ideally with a graphical user interface (GUI), and**to provide lay-level explanation of methods and results **.
I am passionate about making open science accessible: I have adapted my research software to run in an** web-based GUI**[2], authored several plug-and–play**PyPi packages**[3], and published**public-facing blog articles on my research**[4].
I look forward to continuing this work towards**accessible, open science in the AIM program**, and will seek collaborations to broaden and further the impact of our cohort's work.

**REFERENCES:**
[1] Zwetsloot and Dafoe. "Risks From AI" Lawfare Blog, [https://hopth.ru.bp](https://hopth.ru.bp/).
(2019)
[2] Moreno and Ofria. "Multicell. Dig. Evo." Front. Ev. Eco. (2022)
[3] Moreno et al., "hstrat" J. Op. Src. Soft. (2022, in sub.)
[4] Moreno. "Evo. G.–P. Map" BEACON Center Blog, [https://hopth.ru/bo](https://hopth.ru/bo). (2018)
