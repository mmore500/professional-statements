Simulation-based research is increasingly vital to efforts to understand evolutionary processes and the underlying complex real-world problems like infectious disease, antibiotic resistance, cancer treatment, and conservation biology.
However, key research questions involving rare evolutionary events and multi-population ecological interactions remain largely out of reach of existing simulation methods, owing to the immense computational power necessary to perform simulations at these scales.
Emerging hardware accelerators like the 850,000-processor Cerebras Wafer-Scale Engine (WSE) and the 1,472-processor Graphcore Intelligence Processing Unit (IPU) have potential to unleash transformative scale-up of agent-based evolution simulations.
However, these platforms also impose challenging constraints on available per-processor memory and device-to-host communication bandwidth.
This critical methods gap has driven the development of new “DStream” data management algorithms by Postdoc Moreno and PI Zaman.
Although developed for a highly specialized use case, DStream algorithms introduce novel capabilities applicable to a much broader class of “data stream” problems, which arise across numerous embedded and high-performance computing contexts. Undergraduate researcher Yang will lead software development to create public-facing, plug-and-play implementations of DStream algorithms targeting their generalized use case.
This work will substantially expand the impact of the DStream project, as availability of reliable, user-friendly software implementations is a critical factor in driving adoption of novel methods by researchers.

Agent-based evolutionary modeling enables exploration of the big-picture how and why behind incredible biological capability for adaptation, complexity, and novelty.
This field of work, known as "digital evolution," knits interdisciplinary connections between computer science and evolutionary biology to design and study digital processes and structures that capture lifelike properties.
Biologically-inspired techniques leveraging evolution as an algorithm can often produce good solutions to hard real-world problems.
They also provide a useful model system to study difficult questions in evolutionary theory.

My work focuses on understanding organisms' adaptation to the evolutionary process itself ("evolvability") and on developing methodology to simulate larger-scale digital artificial life systems, particularly with respect to high-performance computing and digital multicellularity.
I am particularly passionate about bringing research into practice by building reusable software that advances the field.

## Scaling Up Artificial Life Systems

Studying how artificial evolutionary systems can continually produce novel artifacts of increasing complexity has proven to be a rich vein for practical, scientific, philosophical, and artistic innovations. Unfortunately, existing computational artificial life systems appear constrained by practical limitations on simulation scale.
While by no means certain, the idea that orders-of-magnitude increases in compute power will open up qualitatively different possibilities with respect to open-ended evolution is well founded.

Until fundamental changes to computing technology transpire, scaling up artificial life compute power will require taking advantage of parallel and distributed computing systems.
Modern high-performance scientific computing clusters appear perhaps the best target to start down this path.

Unlike most existing applications of distributed computing in digital evolution, open-ended evolution researchers must prioritize dynamic interactions among distributed simulation elements.
Ecologies, co-evolutionary dynamics, and social behavior all necessitate such dynamic interactions.
The question of how to design artificial life simulations and engineer artifical life software at scale will be paramount for the field.

## Building Accessible, Extendable, and Maintainable Artificial Life Research Software

Open source software supercharges the rate of scientific progress and the applied praxis of those advances.
Interdisciplinary fields like artificial life, which thrive due to contributions from those without formal training in computing such as biologists and mathematicians, especially benefit from published applications and software packages.

Open source devleopment of research software holds core priority within my work, with particular emphasis on maximizing its broader usefullness to the broader community outside of its original context.
Teaching and mentorship also constitues a core aspect of this work, empowering researchers with development capabilities and promoting best practices in the community.
I led the 2020 and 2021 Workshop for Avida-ED Software Development, which paired 27 early-career participants mentored 10 week hands-on projects, most related to writing, testing, and documenting software.
I have also mentored five undergraduates on scientific software development projects.

## Unverstainding Evolvability and Improving It in Digital Evolution Systems

Successful evolutionary search depends on the production of meaningful phenotypic variation that can be inherited by offspring.
Without useful heritable variation evolution stagnates.
The concept of evolvability describes a population's capacity to generate useful heritable phenotypic variation is  of evolvability.
Different evolving systems can exhibit different degrees of evolvability.

Natural systems, in particular, are usually considered to have a capability to continuously generate interesting variation compared to computational
systems.
Understanding --- and replicating -- the evolvability of natural evolution is an open problem in computational evolution research.

Evolvability is desirable in artificial evolution systems for practical ends -- more evolvable systems will help evolutionary algorithms to tackle sophisticated problems more effectively and efficiently.
Understanding evolvability is of great scientific interest for both evolutionary biologists and evolutionary computing researchers, not only for optimization but also with respect to questions related to the evolution of complexity and open-ended evolution.

## Etc.

My current research interests stem directly from my undergraduate thesis and capstone work.
{I am pursing a doctoral degree with Dr. Charles Ofria at BEACON}, an NSF Science and Technology Center for the Study of Evolution in Action at Michigan State University.
BEACON offers access to {high performance computing resources} and a {uniquely interdisciplinary research community}.
Working with biologists on \textit{in vivo} work and with evolutionary computing practitioners will allow me to apply novel biological concepts to evolutionary computing.
In particular, I am interested in understanding what critical nuances are missing from simple algorithmic implementations of evolution built on bare bones selection, variation, and inheritance.
My specific focus is on {evolvability and environmental influence on the phenotype}.
Understanding the relationship between these phenomena will help biologists answer questions about the evolution of complex traits like human intelligence and will help evolutionary computing researchers develop powerful applied evolution techniques to solve practical problems like automating deep learning architecture design.

By probing the algorithmic principles of biology, I hope to contribute to the {development of more capable, versatile AI systems} with direct human impact.
I am inspired by my father, who volunteers for Dial-A-Bus to serve individuals whose disabilities would otherwise limit their ability to fully participate in the community.
I hope that, through applications that counteract disability and free us from dangerous or simply menial tasks, stronger AI will enable people to more fully exercise their human capabilities.
My work with the Swarm lab, with Dr. Chambers, and in the Ofria lab helps lay the groundwork for this future.
I will leverage my outreach skills build industrial collaborations that apply my research to real-world AI problems.

I am committed to {continuing to foster community among scientists and perform STEM outreach}.
I currently volunteer four hours a week as a teacher's assistant in special and general education classrooms in East Lansing.
In my fourth period classroom, my work is specially targeted at engaging minority students.
As I progress in my graduate studies, I look forward to welcoming new graduate students and taking advantage of BEACON funding support to mentor undergraduates on summer research projects.

Ultimately, I aspire to lead an academic research group and build an inclusive community that will allow myself and others to accomplish our outreach, technological, and scientific goals.
GRFP support will help me conduct {cutting-edge research at the intersection of biology and computer science} and lead in the conversation about the {intrinsic value of outreach, mentorship, and community in science}.
Footer

\noindent
\underline{\smash{\textit{{Research History}}}}
I began gaining research experience as a high school student through an {Apprenticeships in Science program} at Oregon State University.
I worked with Dr. John Folwer to investigate the exocyst protein complex in plants.
Using genetic assays and phenotypic measurements, I screened 25 populations of \textit{Arabadopsis thaliana} for synergistic interactions between a known exocyst mutation and a mildly deleterious mutation at an independently-assorting locus.
The group went on to isolate a novel Golgi-localized protein confirmed to interact with the exocyst \cite{fowler}.
I took away a strong impression of what a friendly, supportive, and inclusive scientific community looks like.
This personal experience with STEM outreach motivates my desire to make similar opportunities available to others.

As an undergraduate, I worked at the interface of science and industry at the {USDA small fruits breeding laboratory}.
I spent two summers working full time with Dr. Chad Finn to develop berry cultivars for the fresh fruit and processed food markets.
Achieving widespread production of our cultivars requires buy-in from our partner growers.
To build these relationships, we hosted regular symposiums with brief and actionable presentations on best practices and actively involved growers in our scientific experiments.
I gained further experience making connections between the real word and science through three bouts in the {Mathematical Competition in Modeling} (MCM).
These four-day sprints emphasize pitching insights gained by developing and analyzing mathematical models to business executives and policy makers.
In 2017, my three-person team developed a model of highway traffic in the greater Seattle area and showed that in the near future designating lanes exclusively for autonomous vehicles will reduce commuter travel delays.
We {ranked among the top 11 of over 1,500 participating teams}.
I will continue to use my experience  building collaborative partnerships and gearing science toward a professional audience to translate my research into real-world innovations.

As a sophomore, I built my computational skill set {developing methods for automated isolation of mouse
ultrasonic vocalizations (USVs) from noisy recordings} with Dr. Adam Smith at University of Puget Sound (UPS).
I sought outside funding and was {awarded a NASA space grant of \$3,250} through a competitive application process.
USVs are an important quantitative assay for the affective and social state of mice in biomedical research, but existing software tools were readily confounded by background noise.
I developed and tested filtering algorithms inspired by the Sobel Edge detection method that use human-annotated spectrograms to learn to distinguish between true mouse vocalization signals and background noise.
My approach achieved 75\% accuracy at 25\% recall from noisy recordings.
I presented these results at the 2015 UPS summer research symposium \cite{smith}.
From this experience, I gained computational research skills including data management, version control, and visualization techniques.

I brought my biological and computational interests together studying ant foraging behavior at the {NJIT Swarm lab} in the summer after my junior year.
I was recruited by Drs. Simon Garnier and Jason Graham through the Mathematical Biosciences Institute REU.
For ants on flat terrain, the shortest-distance foraging path, the most energy-efficient foraging path, and the quickest foraging path are all identical.
However, on uneven terrain an obstacle may make the most direct path take longer than a trip that circumvents it.
In the absence of an absolute ``best'' path, the question of how ants make trade-offs is of great interest to biologists and engineers studying swarm robotics.
Thus, I extended computational models of ant foraging to consider uneven terrains.
My differential-equations based model predicts that severe inclines cause ants to favor a more direct, less variable foraging path.
I presented my work at the {2017 Joint Mathematics Meetings} \cite{jmm}.
During my time at the Swarm lab, I was empowered by the autonomy entrusted to me and found the opportunity to answer open biological questions with practical applications rewarding.
After this REU, I saw graduate school as the best way to continue engaging in such self-directed, impactful work.

For my {senior thesis project} at UPS, I worked with Dr. America Chambers to synthesize a conceptual framework for evolvability, the potential for adaptive change to occur in an organism's descendants.
Evolvability has been connected to a wide array of causal factors ranging from gene duplication to phenotypic plasticity.
I organized this constellation of causal factors into three larger classes and analyzed their broad relationships \cite{thesis}.
Building off my thesis, I conducted a {capstone project} to empirically investigate how environmental influence on the phenotype relates to evolvability in a gene-regulatory network model.
I found that populations subjected to stochastic perturbations during the development process evolved a higher incidence of silent mutation.
Further, populations pressured to respond to environmental signals by activating alternate developmental pathways were more sensitive to mutation.
I presented my findings at the 2016 NW Honors Symposium, two campus seminars, and the 2017 NSF BEACON Congress \cite{beacon}.
For my thesis and capstone work, I received the {MacArthur Award for an Outstanding Thesis Presentation} and the {Goman Outstanding Math/CS Senior Award}.
This fall, I have published my thesis work as an illustrated blog series aimed at both the general public and other scientists.
Uniting experiments and theory in my thesis and capstone projects was extremely rewarding;
this work inspired me to continue conducting research that tightly couples these domains.

---
layout: post
title:  "Practical Steps Toward Indefinite Scalability: In Pursuit of Robust Computational Substrates for Open-Ended Evolution"
date:   2020-06-23
---

## Abstract

Studying how artificial evolutionary systems can continually produce novel artifacts of increasing complexity has proven to be a rich vein for practical, scientific, philosophical, and artistic innovations.
Unfortunately, existing computational artificial life systems appear constrained by practical limitations on simulation scale.
The concept of indefinite scalability describes constraints on open-ended systems necessary to incorporate theoretically unbounded computational resources.
Here, we argue that along the path to indefinite scalability, we must consider practical scalability: how can we design open-ended evolutionary systems that make effective use of existing, commercially-available distributed-computing hardware?
We highlight log-time hardware interconnects as a potentially fruitful tool for practical scalability and describe how digital evolution systems might be constructed to exploit physical log-time interconnects.
We extend the DISHTINY digital multicellularity framework to allow cells to establish long-distance cell-cell interconnects that, in implementation, could take advantage of log-time physical interconnects.
We examine two case studies of evolved strains, demonstrating how evolved cells adaptively exploit these interconnects.

## Introduction

The challenge, and promise, of open-ended evolution has animated decades of inquiry and discussion within the artificial life community [[Packard et al., 2019]](#packard2019overview).
The difficulty of devising models that produce characteristic outcomes of open-ended evolution suggests profound philosophical or scientific blind spots in our understanding of the natural processes that gave rise to contemporary organisms and ecosystems.
Already, pursuit of open-ended evolution has yielded paradigm-shifting insights.
For example, novelty search demonstrated how processes promoting non-adaptive diversification can ultimately yield adaptive outcomes that were previously unattainable [[Lehman and Stanley, 2011]](#lehman2011abandoning).
Such work lends insight to fundamental questions in evolutionary biology, such as the relevance --- or irrelevance -- of natural selection with respect to increases in complexity
[[Lehman, 2012](#lehman2012evolution);
[Lynch, 2007](#lynch2007frailty)]
and the origins of evolvability
[[Lehman and Stanley, 2013](#lehman2013evolvability);
[Kirschner and Gerhart, 1998](#kirschner1998evolvability)].
Evolutionary algorithms devised in support of open-ended evolution models also promise to deliver tangible broader impacts on society.
Possibilities include the generative design of engineering solutions, consumer products, art, video games, and AI systems
[[Nguyen et al., 2015](#nguyen2015innovation); [Stanley et al., 2017](#stanley2017open)].

Preceding decades have witnessed advances toward defining --- quantitatively and philosophically --- the concept of open-ended evolution
[[Lehman and Stanley, 2012](#lehman2012beyond); [Dolson et al., 2019](#dolson2019modes);
[Bedau et al., 1998](#bedau1998classification)]
as well as investigating causal phenomena that promote open-ended dynamics such as ecological dynamics, selection, and evolvability
[[Dolson, 2019](#dolson2019constructive);
[Soros and Stanley, 2014](#soros2014identifying);
[Huizinga et al., 2018](#huizinga2018emergence)].
Together, methodological and theoretical advances have begun to yield evidence that the generative potential of artificial life systems is --- at least in part --- meaningfully constrained by available compute resources [[Channon, 2019]](#channon2019maximum).

### Advances in Modern Compute Resources Rely on Distribution and Parallelism

Since the turn of the century, advances in the clock speed of traditional serial processors have trailed off [[Sutter, 2005]](#sutter2005free).
Existing technologies have begun to encounter fundamental constraints including power use and thermal dissipation [[Markov, 2014]](#markov2014limits).
Instead, hardware innovation began to revolve around multiprocessing
[[Hennessy and Patterson, 2011, p.55]](#hennessy2011computer)
and hardware acceleration (e.g., GPU, FPGA, etc.)
[[Che et al., 2008]](#che2008accelerating).
For scientific and engineering applications, individual multiprocessors and accelerators are joined together with fast interconnects to yield so-called high-performance computing clusters s [[Hennessy and Patterson, 2011, p.436]](#hennessy2011computer).
Until fundamental changes to computing technology transpire, scaling up artificial life compute power will require taking advantage of these existing parallel and distributed systems.

### Distributed Hardware in Digital Evolution

Digital evolution practitioners have a rich history of leveraging distributed hardware.
It is common practice to distribute multiple self-isolated instantiations of evolutionary runs over multiple hardware units.
In scientific contexts, this practice yields replicate datasets that provide statistical power to answer research questions [[Dolson and Ofria,
2017]](#dolson2017spatial).
In applied contexts, this practice yields many converged populations that can be scavenged for the best solutions overall [[Hornby et al., 2006]](#hornby2006automated).

Another established practice is to use "island models" where individuals are transplanted between populations that are otherwise independently evolving across distributed hardware.
Koza and collaborators' genetic programming work with a 1,000-cpu Beowulf cluster typifies this approach [[Bennett III et al., 1999]](#bennett1999building).

In recent years, Sentient Technologies spearheaded digital evolution projects on an unprecedented computational scale, comprising over a million CPUs and capable of a peak performance of 9 petaflops [[Miikkulainen et al., 2019]](#miikkulainen2019evolving).
According to its proponents, the scale and scalability of this DarkCycle system was a key aspect of its conceptualization [[Gilbert, 2015]](#gilbert_2015).
Much of the assembled infrastructure was pieced together from heterogeneous providers and employed on a time-available basis [[Blondeau et al., 2012]](#blondeau2012distributed).
Unlike island model where selection events are performed independently on each CPU, this scheme transferred evaluation criteria between computational instances (in addition to individual genomes) [[Hodjat and Shahrzad, 2013]](#hodjat2013distributed).

Sentient Technologies also accelerated the deep learning training process by using many massively-parallel hardware accelerators (e.g., 100 GPUs) to evaluate the performance of candidate neural network architectures on image classification, language modeling, and image captioning problems [[Miikkulainen et al., 2019]](#miikkulainen2019evolving).
Analogous work parallelizing the evaluation of an evolutionary individual over multiple test cases in the context of genetic programming has used GPU hardware and vectorized CPU operations
[[Harding and Banzhaf, 2007b](#harding2007fast2);
[Langdon and Banzhaf, 2019](#langdon2019continuous)].

Existing applications of concurrent approaches to digital evolution distribute populations or individuals across hardware to process them with minimal interaction.
Task independence facilitates this simple, efficient implementation strategy, but precludes application on elements that are not independent.
Parallelizing evaluation of a single individual often emphasizes data-parallelism over independent test cases, which are subsequently consolidated into a single fitness profile.
With respect to model parallelism, Harding has notably applied GPU acceleration to cellular automata models of artificial development systems, which involve intensive interaction between spatially-distributed instantiation of a genetic program [[Harding and Banzhaf, 2007a]](#harding2007fast).
However, in systems where evolutionary individuals themselves are parallelized they are typically completely isolated from each other.

We argue that, in a manner explicitly accommodating capabilities and limitations of available hardware, open-ended evolution should prioritize dynamic interactions between simulation elements situated across physically distributed hardware components.

### Leveraging Distributed Hardware for Open-Ended Evolution

Unlike most existing applications of distributed computing in digital evolution, open-ended evolution researchers should prioritize dynamic interactions among distributed simulation elements.
Parallel and distributed computing enables larger populations and metapopulations.
However, ecologies, co-evolutionary dynamics, and social behavior all necessitate dynamic interactions among individuals.

Distributed computing should also enable more computationally intensive or complex individuals.
Developmental processes and emergent functionality necessitate dynamic interactions among components of an evolving individual.
Even at a scale where individuals remain computationally tractable on a single hardware component, modeling them as a collection of discrete components configured through generative development (i.e., with indirect genetic representation) can promote scalable properties
[[Lipson, 2007]](#lipson2007principles)
such as modularity, regularity, and hierarchy
[[Hornby, 2005](#hornby2005measuring);
[Clune et al., 2011](#clune2011performance)].
Developmental processes may also promote canalization
[[Stanley and Miikkulainen, 2003]](#stanley2003taxonomy),
for example through exploratory processes and compensatory adjustments
[[Gerhart and Kirschner, 2007]](#gerhart2007theory).
To reach this goal, David Ackley has envisioned an ambitious design for modular distributed hardware at a theoretically unlimited scale
[[Ackley and Cannon, 2011]](#ackley2011pursue)
and demonstrated an algorithmic substrate for emergent agents that can take advantage of it
[[Ackley, 2018]](#ackley2018digital).

### A Path of Expanding Computational Scale

While by no means certain, the idea that orders-of-magnitude increases in compute power will open up qualitatively different possibilities with respect to open-ended evolution is well founded.
Spectacular advances achieved with artificial neural networks over the last decade illuminate a possible path toward this outcome.
As with digital evolution, artificial neural networks (ANNs) were traditionally understood as a versatile, but auxiliary methodology --- both techniques were described as "the second best way to do almost anything"
[[Miaoulis and Plemenos, 2008](#miaoulis2008intelligent);
[Eiben, 2015](#eiben2015introduction)].
However, the utility and ubiquity of ANNs has since increased dramatically.
The development of AlexNet is widely considered pivotal to this transformation.
AlexNet united methodological innovations from the field (such as big datasets, dropout, and ReLU) with GPU computing that enabled training of orders-of-magnitude-larger networks.
In fact, some aspects of their deep learning architecture were expressly modified to accommodate multi-GPU training [[Krizhevsky et al., 2012]](#krizhevsky2012imagenet).
By adapting existing methodology to exploit commercially available hardware, AlexNet spurred the greater availability of compute resources to the research domain and eventually the introduction of custom hardware to expressly support deep learning
[[Jouppi et al., 2017]](#jouppi2017datacenter).

Similarly, progress toward realizing artificial life systems with indefinite scalability seems likely to unfold as incremental achievements that spur additional interest and resources in a positive feedback loop with the development of methodology, software, and eventually specialized hardware to take advantage of those resources.
In addition to developing hardware-agnostic theory and methodology, we believe that pushing the envelope of open-ended evolution will analogously require designing systems that leverage existing commercially-available parallel and distributed compute resources at circumstantially-feasible scales.
Modern high-performance scientific computing clusters appear perhaps the best target to start down this path.
These systems combine memory-sharing parallel architectures comprising dozens of cores (commonly targeted using OpenMP
[[Dagum and Menon, 1998]](#dagum1998openmpi)
and low-latency high-throughput message-passing between distributed nodes (commonly targeted using MPI
[[Clarke et al., 1994]](#clarke1994mpi)).

Contemporary scientific computing clusters lack key characteristics required for indefinite scalability: fault tolerance and arbitrary extensibility.
However, they also may offer an opportunity not available in an indefinitely scalable framework: log-time interconnects [[Mollah et al., 2018]](#mollah2018comparative).

### Instantiating Small-World Networks on Parallel and Distributed Hardware

Many natural systems --- such as ecosystems, genetic regulatory networks, and neural networks --- are known to exhibit small-world patterns of connectivity or interaction among components
[[Bassett and Bullmore, 2017](#bassett2017small);
[Fox and Bellwood, 2014](#fox2014herbivores);
[Gaiteri et al., 2014](#gaiteri2014beyond)].
In small-world graphs, mean path length (the number of edges traversed on a shortest-route) between arbitrary components scales logarithmically with system size [[Watts and Strogatz, 1998]](#watts1998collective).
We anticipate that open-ended phenomena emerging across distributed hardware might also involve small-world connectivity dynamics.

What would the impact be of providing a system of hierarchical log-time hardware interconnects as opposed to relying solely on local hardware interconnects?

In Sections
[WAGSW](#wiring-a-generic-small-world-graph),
[WAISO](#wiring-an-ideal-space-filling-hierarchical-tree-without-log-time-physical-interconnects),
[WAISW](#wiring-an-ideal-space-filling-hierarchical-tree-with-log-time-physical-interconnects),
and [WAWSG](#wiring-a-watts-strogatz-graph),
we analyze the scaling relationship between system size and expected node-to-node hops traversed between computational elements interacting as part of an emergent small-world network.
[[Footnote WDWCM]](#footnote-wdwcm)

1. with and without hierarchical log-time physical interconnects between computational nodes, and
2. with computational nodes embedded on one-, two-, or three-dimensional computational meshes.

In [Section WAGSW](#wiring-a-generic-small-world-graph), we find that expected hops over edges weighted by edge betweenness centrality scales polynomially in all cases without hierarchical physical interconnects.
With hierarchical physical interconnects, a logarithmic scaling relationship can be achieved.

In Sections
[WAISO](#wiring-an-ideal-space-filling-hierarchical-tree-without-log-time-physical-interconnects),
[WAISW](#wiring-an-ideal-space-filling-hierarchical-tree-with-log-time-physical-interconnects)
we find that hierarchical physical interconnects yield better best-case mean hops per edge in the case of a one-dimensional computational mesh.
Interestingly, asymptotically better outcomes in two- and three- dimensional meshes cannot be guaranteed by hierarchical physical interconnects.
This suggests that --- even at truly vast scales --- emergent inter-component interaction networks could arise with bounded per-hardware-component messaging load.

In Section [WAWSG](#wiring-a-watts-strogatz-graph) we show that, with a specific traditional construction of small-world graphs, best-case mean hops per edge scales polynomially with graph size.
With hierarchical physical interconnects, a logarithmic scaling relationship can still be achieved.

These theoretical analyses suggest that whether log-time physical interconnects deliver asymptotically better mean connection latency and hop-efficiency depend on the structure of the network overlaid on a spatially-distributed hardware system.
Although we focus on asymptotic analyses, better scaling coefficients might be achieved with long-distance hardware interconnects.
Equivalent asymptotic behavior does not preclude important considerations with respect to performance.

### Exploiting Log-Time Physical Interconnects: a Case Study

What could an artificial life system that exploits log-time hardware interconnects look like?

We present an extension to the DISHTINY platform for studying evolutionary transitions in individuality [[Moreno and Ofria, 2019]](#moreno2019toward).
In previous work with the system, cells situated on a two-dimensional grid interact exclusively with immediate neighbors.
This extension introduces genetic programs that can explicitly-register direct interconnects between (potentially distant) cells for messaging and resource-sharing.
Cells establish these interconnects through a genetically-mediated exploratory growth process.

We report a case study of an evolved strain that adaptively employs interconnects to communicate and selectively distribute resources to the periphery of a multicellular organism.
In Section [CSIM](#case-study-interconnect-messaging), we report another case study of an evolve strain that adaptively employs over-interconnect messaging to selectively suppress somatic cell reproduction.

In future implementations, explicitly-registered cell-cell interconnects may use log-time physical interconnects.
Our prototype implementation exploits shared-memory thread-level parallelism on a single multiprocessor.

### Abstraction, Engineering, and Computational Scale

Although designed with an eye toward scalability, largely along the lines outlined by Ackley, DISHTINY exchanges a uniform, evolutionary-passive substrate for manually-engineered self-replicating cells.
Evolutionary transitions in individuality provide a framework to unite self-replicators and induce meaningful functional synthesis of programmatic components tied to individual compute elements.
This approach mirrors the philosophy of practicality and feasibility laid out by Channon [[Channon, 2019]](#channon2019maximum):

> It is not computationally feasible (even if we knew how) for an OEE simulation to start from a sparse fog of hydrogen and helium and transition to a biological-level era, so it is clearly necessary to skip over or engineer in at least some complex features that arose through major transitions in our universe.

DISHTINY engineers-in some complex features (e.g., cellular structure, genetic transmission of variation, explicitly-registered cell-cell interconnects) in a manner that aims to reflect underlying hardware capabilities (e.g., procedural expression of programs, log-time physical interconnects) so they can be fully utilized.

More granular, less prescriptional approaches seem likely to become preferred when orders of magnitude of more compute power --- toward the extent envisioned by Ackley --- become available.
Such systems will address important questions in their own right about the computational foundations of physical and biological reality.
Current work developing those systems sets the stage for that eventuality [[Ackley, 2018]](#ackley2018digital).

## Methods

Our evolutionary case studies employ an extension to the DISHTINY framework for studying fraternal transitions in individuality.
'Initial work with this system characterized selective pressures for cooperation with kin [[Moreno and Ofria, 2019]](#moreno2019toward).
We have since extended the system to use the SignalGP event-driven genetic programming technique [[Lalejini and Ofria, 2018]](#lalejini2018evolving) to control cell behaviors.
Diverse multicellular life histories evolved in SignalGP-enabled DISHTINY evolutionary trials, involving reproductive division of labor, resource sharing (including, in some treatments, endowment of offspring groups), asymmetrical within-group and inter-group phenomena mediated by cell-cell messaging, morphological patterning, gene-regulation mediated life cycles, and adaptive apoptosis [[Moreno and Ofria, prep]](#dishtinygp).

DISHTINY simulates individual cells, each of which occupies a tile on a toroidal grid.
Cells can reproduce, placing daughter cells into adjoining tiles.
We allow cells the opportunity to engage with kin in a cooperative resource-collection task (Supplementary Section A), which can increase their individual cellular reproduction rates [[Moreno and Ofria, 2020]](#Moreno_Ofria_2020).
Kin groups are explicitly registered: on birth, a cell is either added to its parents group or expelled to establish a new group (Supplementary Section B) [[Moreno and Ofria, 2020]](#Moreno_Ofria_2020).

Cells can differentiate between neighbors that are members of their kin group and neighbors that are not and alter their behavior accordingly.
Each cell contains four SignalGP instances (all executing the same genetic program), one of which controls cell behavior with respect to each neighbor.
These instances may communicate with one another by means of intracellular messaging.
In this work, we add a fifth SignalGP instance to the DISHTINY cell.
This instance can execute special instructions to establish long-distance interconnects with other cells and engage in resource-sharing and/or message passing with those cells.
[Figure AOSHW](#fig-aoshw) summarizes how SignalGP hardware is arranged within DISHTINY cells.

Long-distance interconnects are established through a developmental process, summarized in [Figure IOTDP](#fig-iotdp).
The process begins with the placement of two independent search prongs at the originating cell.
Each prong performs a random walk over the originating cell's kin group, accumulating positive or negative feedback based on tags expressed by underfoot cells.
If a prongs accumulates positive feedback too slowly, it is reset to the location of the better-scoring prong.
Once a positive feedback threshold has been reached, the best-scoring prong develops into a full-fledged connection.
At this point, the originating cell can begin exchanging messages and/or resource over the connection.
Established interconnects may be subsequently removed by either participating cell.

Full details on hardware-level instructions and event-driven environmental cues available to cells are provided in Supplementary Sections D, E, F, and G [[Moreno and Ofria, 2020]](#Moreno_Ofria_2020).


### Evolutionary Screens

Our evolutionary screens consisted of 64 independent evolutionary batches.
We processed each batch in four-hour epochs to enable efficient job scheduling.
Each batch consisted of four isolated 45-by-45 toroidal subpopulations.
Subpopulations were completely intermixed in between four-hour steps.
To facilitate evolutionary search, in addition to a base mutation rate applied to cell division, additional mutations were applied to cells seeding a toroidal grid at the outset of an epoch or budding to form new kin groups during an epoch.

We screened across four-hour checkpoints of replicate batches to see if messages or resource were being sent over interconnects.
We sampled from these populations, performing screens for knockouts of over-interconnect messaging or resource sharing.
We then performed a secondary screen on strains with adaptive over-interconnect messaging or resource sharing to determine if re-routing either messages or shared resources decreased fitness.

We measured relative fitness using competition experiments between strains.
For some competition experiments reported in the case studies, we provide hyperlinks to load a in-browser DISHTINY simulation with the actual strains that were used.
In this web viewer, wild-type strains carry phylogentic root ID 1 and knockout strains carry ID 2.

### Implementation

We implemented our experimental system using the Empirical library for scientific software development in C++, available at [`https://github.com/devosoft/Empirical`](https://github.com/devosoft/Empirical) [[Ofria et al., 2019]](#charles_ofria_2019_2575607).
We used OpenMP to parallelize our main evolutionary replicates, distributing work over two threads.
The code used to perform and analyze our experiments, our figures, data from our experiments, and a live in-browser demo of our system is available via the Open Science Framework at [`https://osf.io/53vgh/`](https://osf.io/53vgh/) [[Foster and Deardorff, 2017]](#foster2017open).

This case study was drawn from epoch 24 of batch 42 of the initial set of evolutionary runs.
We initially considered it for further study due to the presence of widespread over-interconnect resource sharing.
After preliminary knockout experiments confirmed the adaptive significance of both over-interconnect resource-sharing and over-interconnect messaging, we set aside the strain for a case study.
The evolutionary history preceding this case study consumed approximately 96 hours of wall-clock time and 736 compute-core hours.
Approximately 30 million simulation updates and 40,000 cellular generations elapsed.
You can view the strain this case study characterizes in a live in-browser simulation at [`https://mmore500.com/hopto/8`](https://mmore500.com/hopto/8).

Our first step was to evaluate whether the intercellular nature of over-interconnect messaging and resource sharing contributed to this strain's fitness.
(It is possible that messaging and/or resource sharing behaviors might generate stimuli on the recipient or side-effects on the sender that have adaptive consequences whether or not the sender and recipient are distinct cells;
in such a scenario, cells would be just as well off sending messages and/or resource to themselves.)
We performed several competition experiments between the wild-type strain and variants where interconnect messaging and resource sharing was altered to be intracellular instead of intercellular.
At the end of competition experiments, we evaluated the relative abundances of wild-type and variant strains.
In the first variant strain we tested, all outgoing over-interconnect messages were instead delivered to the sending cell.
In 16 out of 16 one-hour competition runs that were seeded half-and-half with the wild-type and variant strains, the wild-type strain drove the variant strain to extinction (one-tailed binomial test; $$p < 0.0001$$; 290 S.D 17 cell gens elapsed).
We observed a similar outcome with a second variant strain where all outgoing over-interconnect resource sharing was rerouted back to the sending cell (14/16 variant strain extinctions; 16/16 wild-type prevalence; 289 S.D. 25 cell gens elapsed).
Finally, a third variant strain where both over-interconnect messaging and over-interconnect resource sharing were returned to the sending cell exhibited the same outcome (16/16 variant strain extinctions; 300 S.D. 23 cell gens elapsed).
The intercellular natures of both over-interconnect messaging and resource sharing appear essential to fitness.

Next, we took a closer look at the evolved cellular mechanisms controlling over-interconnect messaging and resource sharing.
We monitored hardware execution of the wild-type strain in a monoculture population to detect which signals, messages, and fork/call instructions activated each SignalGP module.
We manually cross-referenced this information with a human-readable printout of the strain's genetic program to construct a hypothesized mechanism shown in [Figure B42CS](#fig-b42cs).
We hypothesize that cells at the periphery of a registered kin groups send messages backwards over incoming interconnects that induce interconnect-originating cells to send them resource.
Such a mechanism could preferentially increase resource availability at the group periphery, a region where cell-cell conflict is likely elevated.

We performed a series of four-hour competition experiments between wild type and knockout strains to confirm the adaptive significance of each component of this mechanism.
We began by re-routing stimulus 19, which alerts cells to neighbors that are members of a foreign kin group, to activate a known no-op module.
This knockout strain experienced decreased fitness compared to the wild-type strain (16/16 knockout strain extinctions; one-tailed binomial test; $$p < 0.0001$$; 1996 S.D. 280 cell gens elapsed; [`https://mmore500.com/hopto/ak`](https://mmore500.com/hopto/ak)).
Next, we replaced the over-interconnect messaging instruction that triggers over-interconnect resource-sharing with a no-op instruction.
This knockout strain also experienced decreased fitness (16/16 knockout strain extinctions; 1932 S.D. 223 cell gens elapsed; [`https://mmore500.com/hopto/al`](https://mmore500.com/hopto/al)).
We then replaced all eight copies of the over-interconnect resource-sharing instruction triggered by the over-interconnect messaging with no-op instructions, once more yielding a strain with diminished fitness (16/16 knockout strain extinctions; 1860 S.D. 370 cell gens elapsed; [`https://mmore500.com/hopto/am`](https://mmore500.com/hopto/am)).
Finally, we confirmed the soundness of our fitness competition methodology by running control wild-type versus wild-type competitions.
As expected, we observed no effect of strain ID on competition dominance (8/16 knockout strain extinctions; 8/16 wild-type strain extinctions; one-tailed binomial test; $$p = 0.60$$; 1738 S.D. 217 cell gens elapsed; [`https://mmore500.com/hopto/aj`](https://mmore500.com/hopto/aj)).

## Case Study: Interconnect Messaging

[**Figure B32CS:**](#fig-b32cs){:id="fig-b32cs"}
_Batch 32 case study overview.
Figures B32CS(b) through B32CS(e) are generated from a snapshot of a wild-type strain monoculture population.
In these images, each grid tile represents an individual cell.
Cells are organized into kin groups, color-coded by hue in Figure B32CS(b).
Established interconnects are overlaid in blue on Figure B32CS(c).
In Figures B32CS(d) and B32CS(e), kin groups are outlined in black.
Figure B32CS(d) highlights cells that are sending resource over-interconnect.
Figure B32CS(e) highlights cells that are receiving resource overinterconnect.
You can view an animation of the wild-type monoculutre at [`https://mmore500.com/hopto/an`](https://mmore500.com/hopto/an)._


This case study was drawn from epoch 18 of batch 32 from a secondary set of 64 evolutionary runs.
These runs were identical to the first, except:
* increasing the default outgoing connection cap,
* making cells default-accept instead of default-reject intracellular messages from same-channel cells, and
* removing system-mediated parent-kin-group recognition to promote kin group turnover.

We set this strain aside for case study after preliminary screening suggested that over-interconnect messaging played an adaptive role and that the intercellular nature the messaging of was necessary to that adaptation.
The evolutionary history preceding this case study consumed approximately 72 hours of wall-clock time and 576 compute-core hours.
Approximately 2,197,976 simulation updates and 8,884 cellular generations elapsed.
You can view this case study strain in a live in-browser simulation at [`https://mmore500.com/hopto/7`](https://mmore500.com/hopto/7).

As before, we began by testing whether over-interconnect interaction was adaptive because of its intercellularity.
We performed a competition experiment between the wild-type strain and a variant where over-interconnect messages were re-routed back to the sender.
[[Footnote TWAIR]](#foot-twair)
The wild-type strain was present in greater abundance at the end of all 16 competitions (one-tailed binomial test; $$p < 0.0001$$; 2/16 variant strain extinctions; 52 S.D. 3 cell gens elapsed).
So the adaptiveness of over-interconnect messaging does depend on the intercellular nature of that messaging in this strain.

We proceeded to tease apart the evolved cellular mechanisms this messaging interacts with.
We monitored hardware execution of the wild-type strain in a monoculture population to detect which signals, messages, and fork/call instructions activated each SignalGP module. %shorten because we already said it
% put in common things into case study introduction
Referring to a human-readable printout of the strain's evolved genetic programming, we pieced together the hypothesized mechanism shown in [Figure B32CS](#fig-b32cs).
It appears that neighboring a direct cellular offspring stimulates dispatch of an over-interconnect message that induces the recipient to pause somatic reproduction.

Four-hour competition experiments between wild type and knockout strains allowed us to assess the adaptiveness of each component of this mechanism.
We replaced the instruction responsible for over-interconnect messaging with a no-op instruction and observed a corresponding fitness penalty (16/16 knockout strain extinctions; one-tailed binomial test; $$p < 0.0001$$; 416 S.D. 58 cell gens elapsed; [`https://mmore500.com/hopto/aa`](https://mmore500.com/hopto/aa)).
We also replaced the reproduction-pausing instruction executed in response to over-interconnect messaging with a no-op.
This caused a similar fitness penalty (16/16 knockout strain extinctions; 401 S.D. 29 cell gens elapsed).

To double-check whether messaging specifically over interconnects was key to adaptivity we also competed the wild-type strain against variants with the focal over-interconnect messaging instruction substituted for all other possible module-activating instructions:
* call (378 S.D. 42 cell gens elapsed; [`https://mmore500.com/hopto/ac`](https://mmore500.com/hopto/ac))
* fork (377 S.D. 37 cell gens elapsed; [`https://mmore500.com/hopto/ad`](https://mmore500.com/hopto/ad))
* internal message send (406 S.D. 39 cell gens elapsed; [`https://mmore500.com/hopto/ae`](https://mmore500.com/hopto/ae))
* internal message send-to-all (422 S.D. 30 cell gens elapsed; [`https://mmore500.com/hopto/af`](https://mmore500.com/hopto/af))
* external message send (377 S.D. 37 cell gens elapsed; [`https://mmore500.com/hopto/ag`](https://mmore500.com/hopto/ag))
* external message send-to-all (440 S.D. 32 cell gens elapsed; [`https://mmore500.com/hopto/ah`](https://mmore500.com/hopto/ah))

In each case the substitution variant strain was driven to extinction across all 16 replicate experiments (one-tailed binomial test; $$p < 0.0001$$).

The directionality of messaging over the interconnect, however, does not appear to affect fitness.
We tried substituting the wild-type instruction, which dispatches a message from the terminus of an interconnect to its origin, with an instruction that instead dispatches a message from the origin of an interconnect to its terminus.
In competition against wild-type, the wild type strain was more abundant in only ten of 16 replicate competitions (one-tailed binomial test; $$p = 0.2272$$; 14/16 coalesced to a single strain; 410 S.D. 50 cell gen; [`https://mmore500.com/hopto/ai`](https://mmore500.com/hopto/ai}).

Next we assessed the adaptiveness of the particular spatio-temporal pattern of stimulation induced by incoming over-interconnect  messages.
Does this pattern differ from spatially and temporally random stimulation?
If it does, is the non-uniformity of stimulation adaptive?
To assess these questions, we measured the fraction of cells expressing module 14 in a monoculture wild-type population.
Then, we created a variant strain where outgoing over-interconnect messages from module 5 were disabled and, instead, module 14 activated randomly with probability based on the empirical wild-type activation rate.
[[Footnote BOIBM]](#foot-boibm)
<!-- % between updates 1000 and 1100 updates 40659 paused, 64641 not paused
% 40659/105200 0.3864 paused -->

In effect, this manipulation decouples reproductive pause from the distribution of over-interconnect message delivery and instead couples it to a comparable uniform random distribution.
Indeed, in competition experiments against the wild-type strain this variant fares poorly (15/16 wild-type strain prevalent; 0 variant strain extinctions; one-tailed binomial test; $$p < 0.001$$; 36 S.D. 2 cell gens elapsed), suggesting that the pattern of stimulation induced by over-interconnect messaging is meaningfully non-uniform.
We confirmed this result with a larger-scale set of competition trials (58/64 wild-type strain prevalent; 0 strain extinctions; one-tailed binomial test; $$p < 0.0001$$; 33 S.D. 2 cell gens elapsed).

Does the adaptively non-uniform pattern of stimulation induced by over-interconnect messages depend on non-uniform dispatch of messages from sending cells?
To assess, this question, we measured the per-cell frequency of module 5 activation in a monoculture wild-type population.
We then created a variant strain where outgoing over-interconnect messages from module 5 were disabled.
Instead, the over-interconnect message instruction was randomly executed with uniform per-cell probability based on the empirical wild-type execution rate.
This variant strain held its own against the wild-type strain (5/16 wild-type strain prevalent; 0 strain extinctions; one-tailed binomial test; $$p = 0.9$$; 30 S.D 1 cell gens elapsed).
So, this strain's non-uniform pattern of stimulation seems likely to a result from the actual pattern of cell-cell interconnection rather than selective message dispatch.

We did not find evidence that cells were using tag-based developmental attractors or repulsors to bias connectivity (5/16 wild-type strain prevalent; 0 strain extinctions; $$p=0.9$$; 35 S.D. 8 cell gens elapsed).
However, we did notice frequent interconnect turnover via execution of both remove-incoming and remove-outgoing interconnect instructions.
Substituting these instructions for no-ops yielded a knockout strain with lower fitness than wild-type (13/16 wild-type strain prevalent; 0 strain extinctions; one-tailed binomial test; $$p < 0.05$$; 30 S.D. 11 cell gens elapsed).
We confirmed this result with a larger-scale set of competition trials (60/64 wild-type strain prevalent; 0 strain extinctions; one-tailed binomial test; $$p < 0.0001$$; 39 S.D. 5 cell gens elapsed).
Is this remodeling of connectivity adaptively non-uniform?
We measured the interconnect removal rate in a monoculture wild-type population.
Then, we created a variant strain where interconnect-removal instructions were disabled.
Instead, interconnects in this strain were removed randomly with uniform probability.
In head-to-head competitions, this variant strain did not exhibit diminished fitness (20/64 wild-type strain prevalent; 0 strain extinctions; one-tailed binomial test; $$p = 1.0$$; 30 S.D. 2 cell gens elapsed).

The adaptive mechanism of over-interconnect messaging at play in this strain remains somewhat unclear.
Over-interconnect messaging induces an adaptively non-uniform pattern of module 14 activation.
The transmission of messages *between* cells over the interconnects, in particular, contributes to fitness.
When messages that would be delivered over interconnects are instead re-routed to the sending cell, fitness decreases.
Substituting over-interconnect messaging for local messaging also decreases fitness.
However, message dispatch is effectively random.
This strain employs an adaptive during-lifetime interconnect-remodeling scheme.
However, this remodeling scheme is also effectively random.

Although the process of interconnect development and retention might contribute some sort of spatial and/or temporal bias to module 14 activation, a full characterization of the nature of this bias and the mechanism inducing remains elusive.

## Wiring a Generic Small World Graph

Consider a set of computational nodes arranged in an $$r$$-dimensional mesh.
In each dimension, physical interconnects run between immediately adjacent pairs of nodes.
Represent this physical hardware with a graph $$N$$.
Vertices of $$N$$, $$V(N)$$, represent computational nodes.
Edges of $$N$$, $$E(N)$$, represent physical interconnects between nodes.

Let $$d(a,b)$$ represent the typical number of physical interconnects traversed on a shortest path between a pair of arbitrary nodes $$a, b \in V(N)$$.
This is conceptually equivalent to Manhattan distance.

In the case of a one-dimensional sequence of nodes, for a pair of arbitrary nodes $$a,b \in V(N)$$,
<div>
\begin{equation}
\bar{d}(a,b) \propto |V(N)|.
\end{equation}
</div>

Consider next the case of a higher-dimensional grid topology, like a two-dimensional grid or a three-dimensional mesh.
Because $$d$$ is a Manhattan metric, the number of physical interconnects requiring traversal in each dimension on a shortest-path between two nodes is completely independent.

Arranging the set of nodes $$N$$ in a $$r$$-dimensional cube, cube width in each dimensions scales proportionally to the $$r$$-th root of <span>$$|V(N)|$$</span>.

So, for a pair of arbitrary nodes $$a,b \in V(N)$$,
<div>
\begin{equation*}
\bar{d}(a, b) \propto |V(N)|^{\frac{1}{r}} \times r.
\end{equation*}
</div>

We proceed to construct a small world directed graph $$G$$ using the set of nodes $$N$$ as vertices.
In formal terms, a bijective relationship $$f: V(N) \rightarrow V(G)$$ unites these two sets.
The inverse mapping, $$f^{-1}: V(G) \rightarrow V(N)$$, is also bijective.

Edges in the graph $$G$$ do not represent a physical interconnect.
Instead, edges $$\{\hat{a}, \hat{b}\} \in E(G)$$ represent a close-coordination relationship where node $$\hat{a}$$ frequently interacts with (i.e., dispatches messages to) the destination node $$\hat{b}$$.
[Figure RBACM](#fig-rbacm) illustrates the relationship between $$N$$ and $$G$$.

Let $$\hat{d}(\hat{a},\hat{b})$$ denote distance between vertices $$\hat{a}$$ and $$\hat{b}$$ with respect to the graph $$G$$.
That is, the number of graph edges traversed on a shortest-path route between $$\hat{a}$$ and $$\hat{b}$$ over $$G$$.
In a small-world network, typical graph distance scales proportionally with the logarithm of network size [[Watts and Strogatz, 1998]](#watts1998collective).
In our case, for arbitrary $$\hat{a},\hat{b} \in V(G)$$,
<div>
\begin{equation} \label{eqn:smallworld_prop}
\bar{\hat{d}}(\hat{a},\hat{b}) \propto \log(|V(G)|).
\end{equation}
</div>

Consider the sequence of edges in $$G$$ traversed on a shortest-path route $$R_{\hat{a},\hat{b}}$$ between $$\hat{a}, \hat{b} \in V(G)$$, $$\{\{\hat{v}_1, \hat{v}_2\}, \{\hat{v}_2, \hat{v}_3\}, \ldots, \{\hat{v}_{n-1}, \hat{v}_n\} \}$$.
If we traverse these same nodes over the graph $$N$$ this path would be at least as long as the direct path between $$f^{-1}(\hat{a})$$ and $$f^{-1}(\hat{b})$$ over $$N$$.
(Otherwise, we would violate the Manhattan metric on $$N$$'s triangle inequality.)
Therefore,
<div>
\begin{equation} \label{eqn:path_hops_inequality}
\sum_{\{\hat{v}_i, \hat{v}_{i+1}\} \in  R_{\hat{a},\hat{b}}}
\Big[ d\Big(f^{-1}(\hat{v}_i), f^{-1}(\hat{v}_{i+1})\Big) \Big]
\geq
d\Big(f^{-1}(\hat{a}), f^{-1}(\hat{b})\Big).
\end{equation}
</div>

Recall that $$\hat{a},\hat{b}$$ are sampled uniformly from $$V(G)$$.
So, $$f^{-1}(\hat{a}),f^{-1}(\hat{b})$$ are sampled uniformly from $$V(N)$$.
Thus, Equation \ref{eqn:mesh_prop} allows us to establish the following lower bound,
<div>
\begin{equation*}
d\Big(f^{-1}(\hat{a}), f^{-1}(\hat{b})\Big)
\in
\Omega \Big(
  |V(N)|^{\frac{1}{r}} \times r
\Big).
\end{equation*}
</div>

It follows from Inequality \ref{eqn:path_hops_inequality} that
<div>
\begin{equation*}
\sum_{\{\hat{x}, \hat{y}\} \in  R_{\hat{a},\hat{b}}}
\Big[ d\Big(f^{-1}(\hat{x}), f^{-1}(\hat{y})\Big) \Big]
\in
\Omega \Big(
  |V(N)|^{\frac{1}{r}} \times r
\Big).
\end{equation*}
</div>

Equation \ref{eqn:smallworld_prop} tells us that the mean number of edges in $$R_{\hat{a}, \hat{b}}$$ is proportional to $$\log(|V(G)|)$$.
So, letting $$\bar{d}$$ represent the mean case,
<div>
\begin{equation*}
\log(|V(G)|) \times \bar{d}\Big(f^{-1}(\hat{x}), f^{-1}(\hat{y})\Big)
\in
\Omega \Big(
  |V(N)|^{\frac{1}{r}} \times r
\Big).
\end{equation*}
</div>

Rearranging and simplifying, we arrive at a lower bound of mean distance over the Manhattan network $$N$$ traversed for a connection in the interaction network $$G$$,
<div>
\begin{equation*}
\bar{d}\Big(f^{-1}(\hat{x}), f^{-1}(\hat{y})\Big)
\in
\Omega \Big(
  \frac{
    |V(N)|^{\frac{1}{r}} \times r
  }{
    \log(|V(N)|)
  }
\Big).
\end{equation*}
</div>

Note that edges $$\{\hat{x},\hat{y}\}$$ are not sampled uniformly from $$E(G)$$.
Instead, their sampling is weighted by edge betweenness centrality.
[[Footnote CAPON]](#foot-capon)

## Wiring an Ideal Space-Filling Hierarchical Tree without Log-Time Physical Interconnects

Consider, again, a set of computational nodes arranged in an $$r$$-dimensional mesh.
In each dimension, physical interconnects run between immediately adjacent pairs of nodes.
Let this physical hardware corresponds to a graph $$N$$ where $$V(N)$$ represents computational nodes and $$E(N)$$ represents physical interconnects between nodes.

Let $$d(a,b)$$ represent the typical number of physical interconnects traversed on a shortest path between a pair of arbitrary nodes $$a, b \in V(N)$$.
This is conceptually equivalent to Manhattan distance.

Suppose we have a small-world graph $$G$$ with maximum vertex degree bounded by a finite constant $$m$$.
The vertices of this graph $$G$$ are embedded one-to-one on $$N$$ such that $$|V(G)| = |V(N)|$$.
(Again, along the lines of [Figure RBACM](#fig-rbacm).)


Pick an arbitrary vertex $$a \in V(G)$$.
By the definition of a small-world graph,
<div>
\begin{equation*}
  \frac{1}{|V(G)|} \sum_{v \in V(G)} d(a, v) \propto \log |V(G)|.
\end{equation*}
</div>

Because the degree of the graph $$G$$ is bounded by $$m$$, there must be a subset $$T \subseteq G$$ that, for some branching factor $$k \geq 2$$ forms a complete $$k$$-nary tree rooted at $$a$$ such that
1. the tree height of $$T$$ is <span>$$h \propto \log |V(G)|$$</span> and
2. <span>$$|V(T)| \propto |V(G)|$$</span>.

[Legenstein and Maass](#legenstein2001optimizing) establish a lower bound for the length of wiring required to construct a $$k$$-nary tree with $$n$$ nodes on a one-dimensional $$L_1$$ grid,
<div>
\begin{equation*}
\Omega(n \log n).
\end{equation*}
</div>

In our case, this corresponds to the total number of hops over $$N$$ to traverse every edge in $$T$$.
Because, $$T \subseteq G$$, $$\Omega(n \log n)$$ is also a best-case lower bound for the total number of hops over $$N$$ to traverse every edge in $$G$$.

Because the degree of vertices in $$V(T)$$ is bounded by $$k$$,
<div>
\begin{equation*}
|E(T)| \in O \Big( |V(T)| \Big).
\end{equation*}
</div>

In fact, because the degree of vertices in $$V(G)$$ is also bounded by $$m$$,
<div>
\begin{equation*}
|E(G)| \in O \Big( |V(G)| \Big).
\end{equation*}
</div>

Let the wiring cost of an edge $$\{x, y\}$$ in $$E(G)$$ refer to the number of hops over $$N$$ required to travel from $$x$$ to $$y$$.
The best-case average wiring cost per edge can be computed as the best-case total wiring cost divided by the worst-case number of edges.
For arbitrary $$\{x, y\} \in E(G)$$,
<div>
\begin{eqnarray*}
\bar{d}(x, y)
&\in& \Omega \Big( \frac{ |E(G)| \times \log |E(G)| }{ |E(G)| } \Big)\\
&\in& \Omega \Big( \log |E(G)| \Big).
\end{eqnarray*}
</div>

This result applies to all possible small-world graphs $$G$$ embedded on a one-dimensional computational mesh.

To tractably extend our analysis to three-dimensional meshes, rather than all small-world graphs we will specifically analyze the wiring cost of ideal space-filling trees [[Kuffner and LaValle, 2009]](#kuffner2009space).
This construction efficiently distributes elements of $$G$$ over $$N$$ with respect to wiring cost.
Although this construction potentially represents a lower bound on wiring cost, its optimality has not been concretely established.

For three dimensions, the total length of wiring required as a function of the number of nodes is
<div>
\begin{equation*}
w_3(n)
=
\sum_{i=1}^{\log_8 n} \Big[
  \frac{n}{8^i} % how many to draw
  \times
  \frac{3}{2} \times 8 \times 2^{i} % how big each one is
\Big].
\end{equation*}
</div>

Because
<div>
\begin{equation*}
\lim_{n \rightarrow \infty}
\frac{w_3(n)}{n} = 4,
\end{equation*}
</div>

we have $$w_3(n) \in \Theta \Big( n \Big)$$.
For an $$n$$-node tree, edge count $$|E(G)| \in \Theta \Big( |V(G)| \Big)$$.
So, average edge wiring cost remains constant as $$|V(G)|$$ scales.
Similar analysis concludes an equivalent result in the two-dimensional case.

## Wiring an Ideal Space-Filling Hierarchical Tree with Log-Time Physical Interconnects

Once more, we will work with a mesh of $$n$$ physical hardware nodes corresponding to a graph $$N$$ where $$V(N)$$ represents computational nodes and $$E(N)$$ represents physical interconnects between nodes.
In this case, in addition to physical interconnects between spatially adjacent nodes we will assume a system of hierarchical physical interconnects that allows log-hop traversal between nodes.

Suppose we have a small-world graph $$G$$ with maximum vertex degree bounded by a finite constant $$m$$.
The vertices of this graph $$G$$ are embedded one-to-one on $$N$$ such that $$|V(G)| = |V(N)|$$.
We will specifically construct this graph as an ideal space-filling tree.
[Figure RBACM](#fig-rbacm) illustrates the relationship between $$N$$ and $$G$$.

As a property of this construction, <span>$$|E(N)| \propto |V(N)|$$</span>.

In the best case, where edges in $$E(G)$$ happen to correspond exactly to hierarchical physical interconnects $$E(N)$$, the average hops required per edge is 1.
However, in the worst case the average number of hops over $$N$$ required per edge in $$E(G)$$ is bounded by $$\log_m n$$.

What if, instead of routing all traffic through log-time hierarchical interconnects, we routed traffic between nodes less than $$\log_m n$$ apart through local grid-mesh interconnects?

In this case, we can bound worst-case total wiring cost by
<div>
\begin{equation*}
\sum_{l = 1}^{\log_2 \log_m n} % short edges
\Big[
  m^{\log_m n - l} % number of edges
  \times
  2^l % hop length
\Big]
+
\log_m n % number hops
\times
\sum_{l = \log_2 \log_m n }^{ \log_m n} % long edges
m^{\log_m n - l}.
\end{equation*}
</div>

For the space-filling tree on a one-dimensional mesh, we have $$m = 2$$.
Our upper bound on total wiring cost simplifies to
<div>
\begin{equation*}
w_2(n) =
n \times \log_2 \log_2 n
+
\log_2 n \times (n \times \log_n 4 - 1).
\end{equation*}
</div>

Because
<div>
\begin{equation*}
\lim_{n \rightarrow \infty}
\frac{
  w_2(n)
}{
  n \times \log_2 \log_2 n
}
= 1,
\end{equation*}
</div>
we have $$w_2(n) \in \Theta \Big( n \times \log_2 \log_2 n \Big)$$.
Because edge count $$|E(G)| \in \Theta \Big( n \Big)$$ we can establish the following upper bound on $$\bar{W}(n)$$ mean wiring cost per edge in $$|E(G)|$$ for the one-dimensional case,
<div>
\begin{equation*}
\bar{W}(n) \in \Omega\Big( \log_2 \log_2 n \Big).
\end{equation*}
</div>

What about the three-dimensional case?
For the space-filling tree on a three-dimensional mesh, we have $$m = 8$$.
Our upper bound on total wiring cost simplifies to
<div>
\begin{eqnarray*}
w_8(n)
=& &
\frac{n}{3}
\times (1 - 4^{ \log_2 \log_n 8 }) \\
& &+
\frac{
  (
    n \times 8^{
      \log_2 \log_n 64
    } - 1
  ) \times \log_8 n
}{7}.
\end{eqnarray*}
</div>

Because
<div>
\begin{equation*}
\lim_{n \rightarrow \infty}
\frac{
  w_8(n)
}{
  n
}
= \frac{1}{3},
\end{equation*}
</div>
we have $$w_8 \in \Theta \Big( n \Big)$$.
Once more, because edge count $$|E(G)| \in \Theta \Big( n \Big)$$ we can establish the following upper bound on $$\bar{W}(n)$$ mean wiring cost per edge for the three-dimensional case,
<div>
\begin{equation*}
\bar{W}(n) \in \Omega \Big( 1 \Big).
\end{equation*}
</div>

## Wiring a Watts-Strogatz Graph

Consider a set of computational nodes arranged in an $$r$$-dimensional mesh.
In each dimension, physical interconnects run between immediately adjacent pairs of nodes.
Represent this physical hardware with a graph $$N$$.
Vertices of $$N$$, $$V(N)$$, represent computational nodes.
Edges of $$N$$, $$E(N)$$, represent physical interconnects between nodes.

Let $$d(a,b)$$ represent the typical number of physical interconnects traversed on a shortest path between a pair of arbitrary nodes $$a, b \in V(N)$$.
This is conceptually equivalent to Manhattan distance.

In the case of a one-dimensional sequence of nodes, for a pair of arbitrary nodes $$a,b \in V(N)$$,
<div>
\begin{equation*}
\bar{d}(a,b) \propto |V(N)|.
\end{equation*}
</div>

Consider next the case of a higher-dimensional grid topology, like a two-dimensional grid or a three-dimensional mesh.
Because $$d$$ is a Manhattan metric, the number of physical interconnects requiring traversal in each dimension on a shortest-path between two nodes is completely independent.

Arranging the set of nodes $$N$$ in a $$r$$-dimensional cube, cube width in each dimensions scales proportionally to the $$r$$-th root of <span>$$|V(N)|$$</span>.

So, for a pair of arbitrary nodes $$a,b \in V(N)$$,
<div>
\begin{equation} \label{eqn:mesh_prop}
\bar{d}(a, b) \propto |V(N)|^{\frac{1}{r}} \times r.
\end{equation}
</div>

We proceed to construct a small world directed graph $$G$$ using the set of nodes $$N$$ as vertices.
In formal terms, a bijective relationship $$f: V(N) \rightarrow V(G)$$ unites these two sets.
The inverse mapping, $$f^{-1}: V(G) \rightarrow V(N)$$, is also bijective.

Edges in the graph $$G$$ do not represent a physical interconnect.
Instead, edges $$\{\hat{a}, \hat{b}\} \in E(G)$$ represent a close-coordination relationship where node $$\hat{a}$$ frequently interacts with (i.e., dispatches messages to) the destination node $$\hat{b}$$.
[Figure RBACM](#fig-rbacm) illustrates the relationship between $$N$$ and $$G$$.

Let $$\hat{d}(\hat{a},\hat{b})$$ denote distance between vertices $$\hat{a}$$ and $$\hat{b}$$ with respect to the graph $$G$$.
That is, the number of graph edges traversed on a shortest-path route between $$\hat{a}$$ and $$\hat{b}$$ over $$G$$.
In a small-world network, typical graph distance scales proportionally with the logarithm of network size [[Watts and Strogatz, 1998]](#watts1998collective).
In our case, for arbitrary $$\hat{a},\hat{b} \in V(G)$$,
<div>
\begin{equation*}
\bar{\hat{d}}(\hat{a},\hat{b}) \propto \log(|V(G)|).
\end{equation*}
</div>

Suppose we have a small-world graph $$G$$ constructed over a mesh $$N$$ (as in [Figure RBACM](#fig-rbacm)) using the Watts–Strogatz algorithm.
In this procedure, vertices in $$V(G)$$ corresponding to neighboring computational nodes in $$V(N)$$ are wired together to form a lattice with mean degree $$k$$.
Then, for every vertex $$v \in V(G)$$, each edge $$\{x, y\} \in E(G)$$ containing $$v$$ is reconfigured with probability $$0 < \beta < 1$$ to connect $$v$$ to a randomly-chosen node $$w \in V(G)$$.

Before reconfiguration, the total wiring cost of $$G$$ with respect to hops over $$N$$ was proportional to <span>$$|V(G)|$$</span>.

Recall that, with mesh dimensionality $$r$$ we know that for a pair of arbitrary nodes $$a,b \in V(N)$$,
<div>
\begin{equation*}
\bar{d}(a, b) \propto |V(N)|^{\frac{1}{r}} \times r.
\end{equation*}
</div>

So, after rewiring, the total wiring cost $$w$$ of $$G$$ with respect to hops over $$N$$ can be calculated as
<div>
\begin{equation*}
  \beta |V(G)| \times |V(N)|^{\frac{1}{r}} \times r + (1 - \beta) |V(G)|.
\end{equation*}
</div>

So, <span>$$w \in \Omega \Big( |V(N)|^{\frac{r+1}{r}} \times r \Big)$$</span>.

In this graph, the number of edges is proportional to the graph size $$n$$.

With bounded mean degree, we have $$|E(G)| \propto |V(G)|$$ so we can establish the following lower bound on mean wiring cost per edge of $$G$$ with respect to hops over $$N$$,
<div>
\begin{equation*}
\Omega \Big( |V(G)|^{\frac{1}{r}} \times r \Big).
\end{equation*}
</div>

Note that, with the introduction of log-time hierarchical hardware interconnects into $$N$$ the mean wiring cost per edge of $$G$$ with respect to hops over $$N$$ is bounded in the worst case by <span>$$\Omega \Big( \log |V(G)| \Big)$$</span>.


## Conclusion

Ackley's concept of indefinite scalability lays out an ambitious vision for the computational substrate of future open-ended evolution models.
This vision has inspired researchers to incorporate thinking about underlying computational substrates into open-ended evolution theory and to consider how (or whether) available computational resources meaningfully constrain existing open-ended evolution models.
For the time being, computational substrates for open-ended evolution limited purely by physical (or economic) concerns remain on the horizon, but indefinite scalability has already had concrete, and fruitful, impact on thinking around open-ended evolution.

Although prevalent contemporary computational hardware (and the developer-facing software infrastructure that supports its use) lacks essential features necessary to achieve true indefinite scalability such as fault tolerance and purely relative addressing, many cores designed to support low-latency interconnects.
These high-performance computing resources are increasingly accessible.
Concern over indefinite scalability should not dissuade the design and implementation of open-ended evolution models that accommodate for the limitations of existing hardware and software infrastructure to make effective use of it.
We highlight how log-time hardware interconnects might be exploited in practically scalable, but other model design or implementation tradeoffs may be relevant too (e.g., model dynamics or performance gains that rely on absolute instead of purely relative addressing).

Realizing open-ended evolution models with truly vast computational substrates will require intermediate steps.
Efforts to pursue practical scalability that wrings out contemporary, commercially-available hardware and software infrastructure, will accelerate progress toward realizing truly indefinitely scalable systems.
It seems conceivable that, coupled with innovative model design informed by open-ended evolution theory and effective model implementation in code, contemporary hardware systems and software infrastructure harbor the potential to realize paradigm-shifting advances in open-ended evolution.
As was the case with deep learning, the tipping point of scale for model systems to exhibit qualitatively different behavior may be closer than we assume, perhaps only two or three orders of magnitude.

We highlighted how dynamic interactions within and between evolutionary individuals are crucial to open-ended evolution.
Open-ended evolution models designed to scale computationally should realize these dynamic interactions within a framework that can be efficiently and readily mapped onto parallel computational implementation.
Software tools that enable artificial life researchers to rapidly (and reusably) develop artificial life models have yielded substantial benefit to the field
[[Bohm and Hintze, 2017](#bohm2017mabe);
[Ofria et al., 2019](#charles_ofria_2019_2575607)].
Software tools or frameworks for parallel and distributed artificial life models that are versatile enough to support diverse use cases might help make practical scalability more practical.
In particular, tools to collect data on distributed evolving systems (especially systematics tracking) seem likely to benefit the community.

Here, we presented an extension of the DISHTINY framework as an example of an artificial life system that might hypothetically take advantage of log-time hardware interconnects.
We employed a very modest prototype parallel implementation that used shared-memory parallelism to distribute evolving --- and interacting --- populations of cells over two threads.
We provided a faculty for cells to establish long-distance interconnects over the computational mesh, which in future implementations could rely on hardware-level log-time interconnects.
We have characterized two strains that adaptively employed these interconnects to synthesize spatially-distributed functionality.
In the first case study, messaging and resource sharing over interconnects appeared to facilitate resource recruitment to multicell peripheries.
In a second case study, interconnect messaging played an adaptive role in selectively moderating somatic reproduction.

Incorporating simulation-level objects or physics in open-ended evolution models that explicitly correspond to hardware interconnects represents just one possible approach to exploiting them.
Automatic detection of emergent long-distance interactions across a computational mesh and dynamically re-routing signaling traffic to use hierarchical interconnects might also be possible.
Open-ended evolution models could also be entirely designed around hierarchical interconnects instead of a space-filling computational mesh.

At the core, from both the practical and indefinite standpoints, efforts to scale computational models of open-ended evolution, seek to realize the evolutionary generation of continually novel and increasingly complex artifacts.
As we scale DISHTINY, we are interested in assembling metrics to quantify different aspects of complexity in the system such as organization [[Goldsby et al., 2012]](#goldsby2012task), structure, and function [[Goldsby et al., 2014]](#goldsby2014evolutionary).
We believe that open-ended model systems built on contemporary distributed computational substrates will prove fruitful tools to investigate questions about how biological complexity relates to fitness, genetic drift over elapsed evolutionary time, mutational load, genetic recombination (sex and horizontal gene transfer), ecology, historical contingency, and key innovations.

## Let's Chat

I would love to hear your thoughts on scaling artificial life simulations and studying major transitions in evolution!!

I started a twitter thread (right below) so we can chat :phone: :phone: :phone:

Pop on there and drop me a line :fishing_pole_and_fish: or make a comment :raising_hand_woman:

## Cite This Post

**APA**
> Moreno, M. A., & Ofria, C. (2020, June 25). Practical Steps Toward Indefinite Scalability: In Pursuit of Robust Computational Substrates for Open-Ended Evolution. https://doi.org/10.17605/OSF.IO/53VGH

**MLA**
> Moreno, Matthew A, and Charles Ofria. “Practical Steps Toward Indefinite Scalability: In Pursuit of Robust Computational Substrates for Open-Ended Evolution.” OSF, 25 June 2020. Web.

**Chicago**
> Moreno, Matthew A, and Charles Ofria. 2020. “Practical Steps Toward Indefinite Scalability: In Pursuit of Robust Computational Substrates for Open-Ended Evolution.” OSF. June 25. doi:10.17605/OSF.IO/53VGH.

**BibTeX**
```
@misc{Moreno_Ofria_2020,
  title={Practical Steps Toward Indefinite Scalability: In Pursuit of Robust Computational Substrates for Open-Ended Evolution},
  url={osf.io/53vgh},
  DOI={10.17605/OSF.IO/53VGH},
  publisher={OSF},
  author={Moreno, Matthew A and Ofria, Charles},
  year={2020},
  month={Jun}
}
```

## Footnotes

[Footnote WDWCM](#footnote-wdwcm){:id="footnote-wdwcm"}
Why do we consider mean node-to-node hops per connection?

Although relativistic concerns do ultimately limit latency between spatially-distributed computational elements, with respect to contemporary hardware co-located at a single physical site at foreseeable scales, we expect node-to-node hops to represent an important bottleneck on system performance.

At larger scales, consider the case where emergent connections are embodied via simulation state along the entire path of node-to-node hops traversed by the by the connection (along the line of axon wiring of biological neural networks).
If mean emergent connections per simulation element remain constant as the system scales, then mean node-to-node hops per connection relates to the amount of state required per node to represent connections that pass through it.
(Specifically, if mean node-to-node hops per connection remains constant than the amount of state required per node remains constant.)

Finally, the asymptotic analyses performed on mesh networks without long-distance hierarchical interconnects can be interpreted in terms of Euclidean distance.
(Potentially of interest with respect to relativistic limitations.)

[Footnote BOIBM](#foot-boibm){:id="foot-boibm"}
Because over-interconnect broadcast messages activate all hardware units of a cell, we selected entire cells randomly and activated module 14 on all hardware units.

[Footnote TWAOI](#foot-twaoi){:id="foot-twaoi"}
This was an independent replication of the initial experiment (performed as part of a wider screen) that singled out the case study strain for further analysis.

[Footnote CAPON](#foot-capon){:id="foot-capon"}
Consider all pairings of nodes in a graph.
Now, construct a multiset of paths that, for each possible node pairing, contains the shortest path between those two nodes.
Edge betweenness is the fraction of the paths in this mulitset that passes through a particular edge [[Lu and Zhang, 2013]](#Lu2013).


\section{Introduction}
\label{sec:introoduction;ch:conduit}

The parallel and distributed processing capacity of high-performance computing (HPC) clusters continues to grow rapidly and enable profound scientific and industrial innovations citep{gagliardi2019international}.
These advances in hardware capacity and economy afford great opportunity, but also pose a serious challenge: developing approaches to effectively harness it.
As HPC systems scale, it becomes increasingly difficult to write software that makes efficient use of available hardware and also provides reproducibile results (or even near-perfectly reproducible results --- i.e., up to effects from floating point non-transitivity) consistent with models of computation as being performed a reliable digital machine citep{heroux2014toward}.

The bulk synchronous parallel (BSP) model, which is prevalent among HPC applications citep{dongarra2014applied}, illustrates the challenge.
This model segments fragments of computation into sequential global supersteps, with fragments at superstep $i$ depending only on data from strictly preceding fragments $<i$, often just $i-1$.
Computational fragments are assigned across a pool of available processing components.
The BSP model assumes perfectly reliable messaging: all dispatched messages between computational fragments are faithfully delivered.
In practice, realizing this assumption introduces overhead costs: secondary acknowledgement messages to confirm delivery and mechanisms to dispatch potential resends as the need arises.
Global synchronization occurs between supersteps, with computational fragments held until their preceding superstep has completed citep{valiant1990bridging}.
This ensures that computational fragments will have at hand every single expected input, including those required from fragments located on other processing elements, before proceeding.
So, supersteps only turn over once the entire pool of processing components have completed their work for that superstep.
Put another way, all processing components stall until the most laggardly component catches up.
In a game of double dutch with several jumpers, this would be like slowing the tempo to whoever is most slow-footed each particular turn of the rope.

Heterogeneous computational fragments, with some quick to process and others much slower, would result in poor efficiency under a naive approach where each processing element handled just one fragment.
Some processing elements with easy tasks would finish early then idle while more difficult tasks carry on.
To counteract such load imbalances, programmers can allow for ``parllel slack'' by ensuring computational fragments greatly outnumber processing elements or even performing dynamic load balancing at runtime citep{valiant1990bridging}.

Unfortunately, hardware factors on the underlying processing elements ensure that inherent global superstep jitter will persist: memory access time varies due to cache effects, message delivery time varies due to network conditions, extra processing due to error detection and recovery, delays due to unfavorable process scheduilng by the operating system, etc. citep{dongarra2014applied}.
Power management concerns on future machines will likely introduce even more variability citep{gropp2013programming}.
Worse yet, as we work with more and more processes, the expected magnitude of the worst-sampled jitter grows and grows --- and in lockstep with it, our expected superstep duration.
In the double dutch analogy, with enough jumpers, at almost every turn of the rope someone will need to stop and tie their shoe.
The global synchronization operations underpinning the BSP model further hinder its scalability.
Irrespective of time to complete computational fragments within a superstep, the cost of performing a global synchronization operation increases with processor count citep{dongarra2014applied}.

Efforts to recover scalability by relaxing superstep synchronization fall under two banners.
The first approach, termed ``Relaxed Bulk-Synchronous Programming'' (rBSP), hides latency by performing collective operations asynchronously, essentialy allowing useful computation to be performed at the same time as synchronization primitives for a single superstep percolate through the collective citep{heroux2014toward}.
So, the time cost required to perform that synchronization can be discounted, up to the time taken up by computational work at one superstep.
Likewise, individual processes experiencing heavier workloads or performance degradation due to hardware factors can fall behind by up to a single superstep without slowing the entire colelctive.
However, this approach cannot mask synchronization costs or cumulative performance degradation exceeding a single superstep's duration.
The second approach, termed relaxed barrier synchronization, forgoes global synchronization entirely citep{kim1998relaxed}.
Instead, computational fragments at superstep $i$ only wait on expected inputs from the subset of superstep $i-1$ fragments that they directly interact with.
Imagine a double-dutch routine where each jumper exchanges patty cakes with both neighboring jumpers at every turn of the rope.
Relaxed barrier synchronization would dispense entirely with the rope.
Instead, players would be free to proceed to their next round of patty cakes as soon as they had successfully patty-caked both neighbors.
With $n$ players, player 0 could conceivably advance $n$ rounds ahead of player $n-1$ (each player would be one round ahead of their right neighbor).
Assuming fragment interactions form a graph structure that persists across supersteps, in the general case before causing the entire collective to slow an individual fragment can fall behind at most a number of supersteps equal to the graph diameter citep{gamell2015local}.
Even though this approach can shield the collective from most one-off performance degradations of a single fragment (especially in large-diameter cases), persistently laggard hardware or extreme one-off degradations will ultimately still hobble efficiency.
Dynamic task scheduling and migration aim to address this shortcoming, redistributing work in order to ``catch up'' delinquent fragments citep{acun2014parallel}.
With our double-dutch analogy, we could think of this something like a team coach temporarily benching a jumper who skinned their knee and instructing the other jumpers to pick up their roles in the routine.

In addition to concerns over efficiency, resiliency poses another existential problem to massive HPC systems.
In small scales, it can suffice to assume that such failures occur negligibly, with any that do transpire likely to cause an (acceptably rare) global interruption or failure.
At large scales, however, software crashes and hardware failures become the rule rather than the exception citep{dongarra2014applied} --- running a simulation to completion could even require so many retries as to be practically infeasible.
A typical contemporary approach to imporove resiliency is checkpointing: the sytem periodically records global state then, when a failure arises, progress is rolled back to the most recent global known-good state and runtime restarts citep{hursey2007design}.
Global checkpoint-based recovery is expensive, especially at scale due to overhead associated with regularly recording global state, losing progress since the most recent checkpoint, and actually performing a global teardown and restart procedure.
In fact, at large enough scales global recovery durations could conceivably exceed mean time between failures, making any forward simulation progress all but impossible citep{dongorra2014applied}.
The local failure, local recovery (LFLR) paradigm eschews global recovery by maintaining persistent state on a process-wise basis and providing a recovery function to initialize a step-in replacement process citep{heroux2014toward,teranishi2014toward}.
In practice, such an approach can require keeping running logs of all messaging traffic in order to replay them for the benefit of any potential step-in replacement citep{chakravorty2004fault}.
Returning once more to the double dutch analogy, LFLR would transpire as something like a handful teammates pulling a stricken teammate aside to catch them up after an amnesia attack (rather than starting the entire team's routine back at the top of the current track).
The intervening jumpers would have to remind the stricken teammate of a previously recorded position then discreetly re-feigning some of their moves that the stricken teammate had cued off between that recorded position and the amnesia episode.

The possibility of multiple simultaneous failure (perhaps, for example, of dozens of processes resident on a single node) poses an even more difficult, although not insurmountable, challenge for LFLR that would likely necessitate even greater overhead.
On approach involves pairing up with a remote ``buddy'' process to hang on to a process' snapshots to be carbon-copied on all of that process' messages in order to ensure an independently survivable log.
Unfortunately, this could potentialy forwarding all messaging traffic between simulation elements coresident on the focal process to its buddy, dragging inter-node communication into some otherwise trivial simulation operations citep{chakravorty2007fault}.
Efforts to ensure resiliency beyond single-node failures currently appear unnecessary citep[p. 12]{ni2016mitigation}.
Even though LFLR saves the cost of global spin-down and spin-up, all processes will potentially have to wait for work lost since the last checkpoint to be recompleted, although in some cases this could be helped along by tapping idle hardware to take over delinquent work from the failed process and help catch it up citep{dongarra2014applied}.

Still more insidious to the reliable digital machine model, though, are soft errors --- events where corruption of data in memory occurs, usually do to environmental interferience (i.e., ``cosmic rays'') citep{karnik2004characterization}.
Further miniaturization and voltage reduction, which are assumed as a likely vehicle for continuing advances in hardware efficiency and performance, could conceivably  worsen susceptibility to such errors citep{dongarra2014applied,kajmakovic2020challenges}.
What makes soft errors so dangerous is their potential indetectability.
Unlike typical hardware or software failures, which explicitly result in an explicit, observable outcome (i.e., an error code, an exception, or even just a crash), soft errors can transpire silently and lead to incorrect computational results without leaving anyone the wiser.
Luckily, soft errors they occur rarely enough to be largely negelcted in most single-processor applications (except the most safety-critical settings); however, at scale soft errors occur at a non-trivial rate
citep{sridharan2015memory,scoles2018cosmic}.
Redundancy (be it duplicated hardware components or error correction codes) can reduce the rate of uncorrected (or at least undetected) soft errors, although at a non-trivial cost citep{vankeirsbilck2015soft,sridharan2015memory}.
In some application domains with symmetries or conservation principles the rate of soft errors (or, at least, silent soft errors) could be also reduced through so-called ``skeptical'' assertions at runtime citep{dongorra2014applied}, although this too comes at a cost.

Even if soft errors can be effectively eradicated --- or at least suppressed to a point of inconsequentiality --- the nondeterministic mechanics of fault recovery and dynamic task scheduling could conceivably make guaranteeing bitwise reprodicibility at exascale effectively impossible, or at least an unreasonable engineering choice citep{dongarra2014applied}.
However, the assumption of the reliable digital machine model results remains near-universal within parallel and distributed algorithm design citep{chakradhar2010best}.
Be it costly or simply a practical impossibility, the worsening burden of synchronization, fault recovery, and error correction begs the question of whether it is viable to maintain, or even to strive to maintain, the reliabile digital machine model at scale.
Indeed, software and hardware that relaxes guarantees of correctness and determinism --- a so-called ``best-effort model'' --- have been shown to improve speed citep{chakrapani2008probabilistic}, energy efficiency citep{chakrapani2008probabilistic,bocquet2018memory}, and scalability citep{meng2009best}.
As technology advances, computing is becoming more distributed and we are colliding with physical limits for speed and reliability.
%Theoretical exploration of constraints distributed systems will face at the asymptote of technological (and even physical) constraints, performed under the banner of ``indefinite scalability'' in citep{ackley2011pursue}, highlights an essential role --- at large enough scales, essentially a design inevitability --- for best-effort methods.
%Specifically, this theory finds as necessary asynchronous operation and graceful degradation under hardware failure (in addition to decentralized networking and interchangeable hardware components).
Massively distributed systems are becominging inevitable, and indeed if we are to truly achieve ``indefinite scalability'' citep{ackley2011pursue} we must shift from guaranteed acuracy to best-effort methods that operate asynchronously and degrade gracefully under hardware failue.

The suitability of the best-effort model varies from application to application.
Some domains are clear cut in favor of the reliable digital machine model --- for example, due to regulatory issues citep{dengorra2014applied}.
However, a subset of HPC applications can tolerate --- or even harness --- occasionally flawed or even fundamentally nondeterministic computation citep{chakradhar2010best}.
Various approximation algorithms or heuristics fall into this category, with notable work being done on best-effort stochastic gradient descent for artificial neural network applications citep{dean2012large,zhao2019elastic,niu2011hogwild,noel2014dogwild}.
Best-effort, real-time computing approaches have also been used in some artificial life models citep{ray1995proposal}.
Likewise, algorithms relying on pseudo-stochastic methods that tend to exploit noise (rather than destabilize due to it) also make good candidates citep{chakrapani2008probabilistic,chakradhar2010best}.
Real-time control systems that cannot afford to pause or retry, by necessity, fall into the best-effort category citep{rahmati2011computing}.

This work distills best-effort communication from the larger issue of best-effort computing, paying it special attention and generally pretermiting the larger issue.
Specifically, we investigate the implications of relaxing synchronization and message delivery requirements.
Under this model, the runtime strives to minimize message latency and loss, but guarantees elimination of neither.
Instead, processes continue their compute work unimpeded and incorporate communication from collaborating processes as it happens to become available.
We still assume that messages, if and when they are delivered, retain contentual integrity.
We see best-effort communication as a particularly fruitful target for investigation.
Firstly, synchronization constitutes the root cause of many contemporary quotidien scaling bottlenecks, well below the mark of thousands or millions of cores where runtime failures and soft errors become critical coniderations.
Secondly, a best-effort approach  challenges of heterogenous, varying (i.e., due to power management), and generally lower communication bandwidth (relative to compute) expected on future HPC hardware citep{gropp2013programming, acun2014parallel}.
A best-effort communication model presents the possibility of runtime adaptation to effectively utilize available resources given the particular ratio of compute and communication capability at any one moment in any one rack.

Complex biological organisms exhibit characteristic best-effort properties: trillions of cells interact asynchronously while overcoming all but the most extreme failures in a noisy world.
As such, bio-inspired algorithms present strong potential to benefit from best-effort communication strategies.
For example, evolutionary algorithms commonly use guided stochastic methods (i.e., selection and mutation operators) resulting in a search process that does not guarantee optimality, but typically produces a diverse range of high-quality results.
Indeed, island model genetic algorithms are easy to parallelize and have been shown to perform well with asynchronous migration citep{izzo2009parallel}.
Likewise, artificial life simulations commonly rely on a bottom-up approach and seek to model life-as-it-could-be evolving in a noisy environment akin to the natural world, yet distinct from it citep{bonabeau1994we}. % rather than the implications of certain mechanistic assumptions
Although perfect reproducibility and observability have uniquely enabled digital evolution experiments to ask and answer otherwise intractable questions citep{pontes2020evolutionary,lenski2003evolutionary,grabowski2013case,dolson2020interpreting,fortuna2019coevolutionary,goldsby2014evolutionary,covert2013experiments,zaman2011rapid,bundy2021footprint,dolson2017spatial}, the reliable digital machine model is not strictly necessary for all such work.
Issues of distributed and parallel computing are of special interest within the the artificial life subdomain of open-ended evolution (OEE) citep{ackley2014indefinitely}, which studies long-term dynamics of evolutionary systems in order to understand factors that affect potential to generate ongoing novelty citep{taylor2016open}.
Recent evidence suggests that the generative potential of at least some model systems are --- at least in part --- meaningfully constrained by available compute resources citep{channon2019maximum}.

Much exciting work on best-effort computing has incorporated bespoke experimental hardware citep{chippa2014scalable, ackley2011homeostatic, cho2012ersa, chakrapani2008probabilistic}.
However, here, we focus on exploring best-effort communication among parallel and distributed elements within existing, commercially-available hardware.
Existing software libraries, though, do not explicitly expose a convenient best-effort communication interface for such work.
As such, best-effort approaches remain rare in production software and efforts to study best-effort communication must make use of a combination of limited existing support and the development of new software tools.

The Message Passing Interface (MPI) standard citep{gropp1996high} represents the mainstay for high-performance computing applications.
This standard exposes communication primitives directly to the end user.
MPI's nonblocking communication primitives, in particular, are sufficient to program distributed computations with relaxed synchronization requirements.
Although its explicit, the imperative nature of the MPI protocols enables precise control over execution; unfortunately it also poses significant expense in terms of programability.
This cost manifests in terms of reduced programmer productivity and software quality, while increasing domain knowledge requirements and the effort required to tune for performance due to program brittleness citep{gu2019comparative, tang2014mpi}.

In response to programmability concerns, many frameworks have arisen to offer useful parallel and distributed programming abstractions.
Task-based frameworks such as Charm++ citep{kale1993charm++}, Legion citep{bauer2012legion}, Cilk citep{blumofe1996cilk}, and Threading Building Blocks (TBB) citep{reinders2007intel} describe the dependency relationships among computational tasks and associated data and relies on an associated runtime to automatically schedule and manage execution.
These frameworks assume a deterministic relationship between tasks.
In a similar vein, programming languages and extensions like Unified Parallel C (UPC) citep{el2006upc} and Chapel citep{chamberlain2007parallel} rely on programmers to direct execution, but equips them with powerful abstractions, such as global shared memory.
However, Chapel's memory model explicitly forbids data races and UPC ultimately relies on a barrier model for data transfer.

To bridge these shortcomings, we employ a new software framework, the Conduit C++ Library for Best-Effort High Performance Computing citep{moreno2021conduit}.
The Conduit library provides tools to perform best-effort communication in a flexible, intuitive interface and uniform inter-operation of serial, parallel, and distributed modalities.
Although Conduit currently implements distributed functionality via MPI intrinsics, in future work we will explore lower-level protocols like InfiniBand Unreliable Datagrams citep{kashyap2006ip, koop2007high}.

Here, we present a set of on-hardware experiments to empirically characterize Conduit's best-effort communication model.
First, we determine whether best-effort communication strategies can benefit performance compared to the traditional perfect communication model.
We also tested two intermediate, partially synchronized modes: one where the processor pool completed a global barrier (i.e., they aligned at a sychronization point) at predetermined, rigidly scheduled timepoints and another where global barriers occurred on a rolling basis spaced out by fixed-length delays from the end of the last synchronization.%
This approach prevents interference from shifts in processes' workload profiles in observation of the effects of scaling up processor count.
In order to survey across workload profiles, we tested performance under both a communication-intensive graph coloring solver and a compute-intensive artificial life simulation.
To survey across hardware configurations, we tested scaling CPU count via threading on a single node and scaling via multiprocessing with each process assigned to a distinct node.

Second, we sought to more closely characterize variability in message dispatch, transmission, and delivery under the best-effort model.
Unlike perfect communication, under the best-effort model real-time volatility affects the outcome of computation.
magnitude and spatiotemporal distribution of variability
Because real-time processing speed degradations and message latency or loss alters which inputs each particular $i$th computational fragment sees, characterizing these phenomena's distribution across processing components and over time is critical to understanding the actual computation being performed.
% @CAO: This sentence needs some work -- I'm not sure what you're trying to say here.
% @MAM: better?
For example, consistently faster execution or lower messaging latency for some subset of processing elements would violate any uniformity or symmetry assumptions within a simulation.
It is even possible to imagine reciprocal interactions between real-time best-effort dynamics and simulation state.
In the case of a positive feedback loop, the magnitude of effects might become extreme.
For example, in artificial life scenarios, agents may evolve strategies that selectively increase messaging traffic so as to encumber neighboring processing elements or even cause important messages to be dropped.

Digital evolution techniques compliment traditional wet-lab evolution experiments by enabling researchers to address questions that would be otherwise limited by:

    reproduction rate (which determines the number of generations that can be observed in a set amount of time),
    incomplete observations (every event in a digital system can be tracked),
    physically-impossible experimental manipulations (every event in a digital system can can be arbitrarily altered), or
    resource- and labor-intensity (digital experiments and assays can be easily automated).

The versatility and rapid generational turnover of digital systems can easily engender a notion that such systems can already operate at scales greatly exceeding biological evolution experiments. Although digital evolution techniques can feasibly simulate populations numbering in the millions or billions, very simple agents and/or very limited agent-agent interaction. With more complex agents controlled by genetic programs, neural networks, or the like, feasible population sizes dwindle down to thousands or hundreds of agents.

## Putting Scale in Perspective

Take Avida as an example. This popular software system that enables experiments with evolving self-replicating computer programs. In this system, a population of ten thousand can undergo about twenty thousand generations per day. This means that about two hundred million replication cycles are performed in a day [Ofria et al., 2009].

Each flask in the Lenski Long-Term Evolution Experiment hosts a similar number of replication cycles. In their system, E. coli undergo about six doublings per day. Effective population size is reported as 30 million [Good et al., 2017]. Hence, about 180 million replication cycles elapse per day.

Likewise, in Ratcliff’s work studying the evolution of multicellularity in S. cerevisiae, about six doublings per day occur among a population numbering on the order of a billion cells [Ratcliff, 2012]. So, around six billion cellular replication cycles elapse per day in this system.

Although artificial life practitioners traditionally describe instances of their simulations as “worlds,” with serial processing power their scale aligns (in naive terms) more along the lines of a single flask. Of course, such a comparison neglects the disparity between Avidians and bacteria or yeast in terms of genome information content, information content of cellular state, and both quantity and diversity of interactions with the environment and with other cells.

Recent work with SignalGP has sought to address some of these shortcomings by developing digital evolution substrates suited to more dynamic environmental and agent-agent interactions [Lalejini and Ofria, 2018] that more effectively incorporate state information [Lalejini et al., 2020; Moreno, 2020]. However, to some degree, more sophisticated and interactive evolving agents will necessarily consume more CPU time on a per-replication-cycle basis — further shrinking the magnitude of experiments tractable with serial processing.

## The Future is Plastics Parallel

Throughout the 20th century, serial processing enjoyed regular advances in computational capacity due to quickening clock cycles, burgeoning RAM caches, and increasingly clever packing together of instructions during execution. Since, however, performance of serial processing has bumped up against apparent fundamental limits to computing’s current technological incarnation [Sutter, 2005]. Instead, advances in 21st century computing power have arrived via multiprocessing [Hennessy and Patterson, 2011, p.55] and hardware acceleration (e.g., GPU, FPGA, etc.) [Che et al., 2008].

Contemporary high-performance computing clusters link multiprocessors and accelerators with fast interconnects to enable coordinated work on a single problem [Hennessy and Patterson, 2011, p.436]. High-end clusters already make hundreds of thousands or millions of cores available. More loosely-affiliated banks of servers can also muster significant computational power. For example, Sentient Technologies notably employed a distributed network of over a million CPUs to run evolutionary algorithms [Miikkulainen et al., 2019].

The availability of orders of magnitude greater parallel computing resources in ten and twenty years’ time seems probable, whether through incremental advances with traditional silicon-based technology or via emerging, unconventional technologies such as bio-computing [Benenson, 2009] and molecular electronics [Xiang et al., 2016]. Such emerging technologies could make greatly vaster collections of computing devices feasible, albeit at the potential cost of component-wise speed [Bonnet et al., 2013; Ellenbogen and Love, 2000] and perhaps also component-wise reliability.


## What of Scale?

Parallel and distributed computing has long been intertwined with digital evolution [Moreno and Ofria, 2020]. Practitioners typically proceed along the lines of the island model, where subpopulations evolve in parallel with intermittent exchange of individuals [Bennett III et al., 1999]. Similarly, in scientific contexts, absolute segregation is often enforced between parallel subpopulations to yield independent replicate datasets [Dolson and Ofria, 2017].

These techniques can enable observation of rare events and provide statistical power to answer research questions. However, evolving subpopulations in parallel does not lend itself to large-scale study of interaction-driven phenomena such as

    multicellularity,
    sociality, and
    ecologies.

These topics are of interest in digital evolution and artificial life, particularly with respect to the issue of open-ended evolution. While by no means certain, it seems plausible that orders-of-magnitude increases in system scale will enable qualitatively different experimental possibilities [Moreno and Ofria, 2020].

So, how can we exploit parallel computing power in digital evolution systems revolving around such interaction-driven phenomena? Addressing this question will be key both to enabling digital evolution to take full advantage of already-available contemporary computational resources and to positioning digital evolution to exploit vast computational resources that will likely become available in the not-too-distant future.

Alife making trade-offs about reproducibiltiy/determinism, observability, etc. etc.

Test [@vostinar2024empirical]
